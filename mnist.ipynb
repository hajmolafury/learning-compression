{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "#To install plotpy library:\n",
    "#pip install plotly --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\",one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_hl1=1000\n",
    "nodes_hl2=1000\n",
    "n_classes=10\n",
    "batch_size=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=tf.placeholder('float',[None,784])\n",
    "y=tf.placeholder('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(data):\n",
    "    hl1={'weights':tf.Variable(tf.random_normal([784,nodes_hl1])),'bias':tf.Variable(tf.random_normal([nodes_hl1]))}\n",
    "    hl2={'weights':tf.Variable(tf.random_normal([nodes_hl1,nodes_hl2])),'bias':tf.Variable(tf.random_normal([nodes_hl2]))}\n",
    "    output_layer={'weights':tf.Variable(tf.random_normal([nodes_hl2,n_classes])),'bias':tf.Variable(tf.random_normal([n_classes]))}\n",
    "    #(input_data*weights +bias)\n",
    "    #using activation function as ReLU\n",
    "    l1=tf.add(tf.matmul(data,hl1['weights']),hl1['bias'])\n",
    "    l1=tf.nn.relu(l1)\n",
    "                                                                                        \n",
    "    l2=tf.add(tf.matmul(l1,hl2['weights']),hl2['bias'])\n",
    "    l2=tf.nn.relu(l2)\n",
    "                                                                                           \n",
    "    output=tf.add(tf.matmul(l2,output_layer['weights']),output_layer['bias'])\n",
    "                                                                                           \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55000"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_dir = '/tmp/tensorflow/mnist'\n",
    "mnist.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epoch=30\n",
    "f=2\n",
    "epoch_loss=np.zeros(num_epoch)\n",
    "test_acc=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_neural_network(x):\n",
    "    prediction=neural_network(x)\n",
    "    cost=tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=prediction,labels=y))\n",
    "    \n",
    "    optimizer=tf.train.AdamOptimizer().minimize(cost)\n",
    "    #tf.summary.scalar('cost',cost)\n",
    "   \n",
    "    with tf.Session() as sess:\n",
    "        #train_writer = tf.summary.FileWriter(summary_dir + '/train',sess.graph)\n",
    "        #test_writer = tf.summary.FileWriter(summary_dir + '/test',sess.graph)\n",
    "        #merged = tf.summary.merge_all()\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        #merged=tf.summary.merge_all()\n",
    "        \n",
    "        for epoch in range(num_epoch):\n",
    "           \n",
    "            for i in range(int(mnist.train.num_examples/batch_size)):\n",
    "                batch_x,batch_y=mnist.train.next_batch(batch_size)\n",
    "                _, c=sess.run([optimizer, cost],feed_dict={x:batch_x,y:batch_y})\n",
    "                epoch_loss[epoch]+=c\n",
    "            \n",
    "                #train_writer.add_summary(summary,i,epoch)\n",
    "                if i%int((int(mnist.train.num_examples/batch_size)/f))==0:\n",
    "                    correct=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "                    accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
    "                    test_acc.append(accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "            \n",
    "            print ('Epoch', epoch+1,'completed out of',num_epoch,'loss:',epoch_loss[epoch])\n",
    "            print (time.time() - start_time, 'sec')\n",
    "                \n",
    "#         correct=tf.equal(tf.argmax(prediction,1),tf.argmax(y,1))\n",
    "#         accuracy=tf.reduce_mean(tf.cast(correct,'float'))\n",
    "#         tf.summary.scalar('accuracy',accuracy)\n",
    "#         print('accuracy :',accuracy.eval({x:mnist.test.images,y:mnist.test.labels}))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 completed out of 30 loss: 202373.6941576004\n",
      "13.82559609413147 sec\n",
      "Epoch 2 completed out of 30 loss: 52240.040556902066\n",
      "22.884214162826538 sec\n",
      "Epoch 3 completed out of 30 loss: 28737.23848864436\n",
      "32.06090712547302 sec\n",
      "Epoch 4 completed out of 30 loss: 16293.072530255304\n",
      "41.46075105667114 sec\n",
      "Epoch 5 completed out of 30 loss: 9959.414911266273\n",
      "51.05084705352783 sec\n",
      "Epoch 6 completed out of 30 loss: 6470.603584134855\n",
      "61.6993989944458 sec\n",
      "Epoch 7 completed out of 30 loss: 4935.773208344019\n",
      "72.29271006584167 sec\n",
      "Epoch 8 completed out of 30 loss: 3780.830595511128\n",
      "82.73738598823547 sec\n",
      "Epoch 9 completed out of 30 loss: 3262.509975385874\n",
      "92.96575713157654 sec\n",
      "Epoch 10 completed out of 30 loss: 3022.774283845656\n",
      "103.29224300384521 sec\n",
      "Epoch 11 completed out of 30 loss: 3451.7840214311186\n",
      "113.64941906929016 sec\n",
      "Epoch 12 completed out of 30 loss: 3197.096623227212\n",
      "123.59376907348633 sec\n",
      "Epoch 13 completed out of 30 loss: 2360.844452847418\n",
      "134.13972997665405 sec\n",
      "Epoch 14 completed out of 30 loss: 2309.7589253882884\n",
      "143.67186498641968 sec\n",
      "Epoch 15 completed out of 30 loss: 2241.744173191748\n",
      "153.55708718299866 sec\n",
      "Epoch 16 completed out of 30 loss: 1995.5750239582967\n",
      "163.17908310890198 sec\n",
      "Epoch 17 completed out of 30 loss: 1904.8235065986157\n",
      "173.0515410900116 sec\n",
      "Epoch 18 completed out of 30 loss: 1349.0973361479878\n",
      "182.84127020835876 sec\n",
      "Epoch 19 completed out of 30 loss: 1614.559362490557\n",
      "193.07425689697266 sec\n",
      "Epoch 20 completed out of 30 loss: 1659.2601042262786\n",
      "203.6322021484375 sec\n",
      "Epoch 21 completed out of 30 loss: 1804.6529776120965\n",
      "213.79916310310364 sec\n",
      "Epoch 22 completed out of 30 loss: 1467.3079599770213\n",
      "223.72303199768066 sec\n",
      "Epoch 23 completed out of 30 loss: 1238.928426398709\n",
      "234.7992720603943 sec\n",
      "Epoch 24 completed out of 30 loss: 1464.92278293259\n",
      "244.6894428730011 sec\n",
      "Epoch 25 completed out of 30 loss: 1517.6748903187377\n",
      "255.27512097358704 sec\n",
      "Epoch 26 completed out of 30 loss: 1407.5886461130508\n",
      "265.0661358833313 sec\n",
      "Epoch 27 completed out of 30 loss: 1088.057394287916\n",
      "274.6822102069855 sec\n",
      "Epoch 28 completed out of 30 loss: 911.0982350984201\n",
      "284.92598009109497 sec\n",
      "Epoch 29 completed out of 30 loss: 1036.777111858428\n",
      "295.29308700561523 sec\n",
      "Epoch 30 completed out of 30 loss: 930.8178874276032\n",
      "305.8290641307831 sec\n",
      "Training Over. \n",
      "Now you are a SuperSaiyan\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "if __name__==\"__main__\":\n",
    "    start_time=time.time()\n",
    "    train_neural_network(x)\n",
    "    print (\"Training Over. \\nNow you are a SuperSaiyan\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.1.1\n"
     ]
    }
   ],
   "source": [
    "from plotly import __version__\n",
    "from plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\n",
    "\n",
    "print (__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly\n",
    "plotly.tools.set_credentials_file(username='ymehta95', api_key='TVHPG5E24omQeUyWougP')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_axis1=[]\n",
    "x_axis2=[]\n",
    "for i in range(num_epoch):\n",
    "    x_axis1.append(i+1)\n",
    "    \n",
    "for i in range(num_epoch*f):\n",
    "    x_axis2.append((i)/f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ymehta95/10.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace0=go.Scatter(x=x_axis1,y=epoch_loss)\n",
    "trace1=go.Scatter(x=x_axis2,y=test_acc)\n",
    "data=([trace0])\n",
    "py.iplot(data,filename='mnist_adam_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~ymehta95/8.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=([trace1])\n",
    "py.iplot(data,filename='mnist_adam_acc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
